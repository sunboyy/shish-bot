{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Stopword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "def clean_stopword(text):\n",
    "    # Apply this code to every textual string\n",
    "    word_list = text.split() \n",
    "    filtered_words = [word for word in word_list if word not in stopwords.words('english')]\n",
    "    text = ' '.join(filtered_words)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remove Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "print(string.punctuation)\n",
    "\n",
    "def remove_punc(text):\n",
    "    punctuation = set(string.punctuation)\n",
    "    except_punc = ['?', '!', '\\\"', ',', '.']\n",
    "    for ex in except_punc:\n",
    "        punctuation.remove(ex)\n",
    "    out = []\n",
    "#     print(list(text))\n",
    "#     out = [e for e in list(text) if e not in punctuation]\n",
    "    for e in list(text):\n",
    "\n",
    "        if e in except_punc:\n",
    "            if e != '.' :\n",
    "                out.append(\" \"+e)\n",
    "            else :\n",
    "                out.append(\".\")\n",
    "        elif e not in punctuation or e is '\\'':\n",
    "            out.append(e)\n",
    "        else :\n",
    "            out.append(\" \")\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decontracrion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def decontracted(phrase):\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "\n",
    "    # general\n",
    "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
    "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
    "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split contraction (include 'em 'til)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def split_contraction(phrase):\n",
    "    # convert two types of single qoute\n",
    "    phrase = re.sub(r\"’\", \"'\", phrase)\n",
    "    # specific\n",
    "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
    "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"\\'em \", \"them \", phrase)\n",
    "    phrase = re.sub(r\"\\'til\", \"until\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"y\\'\", \" you \", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"in'\", \"ing\", phrase)\n",
    "    \n",
    "    # general\n",
    "\n",
    "    phrase = re.sub(r\"n \\'t\", \" n\\'t\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"n\\'t\", \" n\\'t\", phrase)\n",
    "    phrase = re.sub(r\"\\'re\", \" 're\", phrase)\n",
    "    phrase = re.sub(r\"\\'s\", \" 's\", phrase)\n",
    "    phrase = re.sub(r\"\\'d\", \" 'd\", phrase)\n",
    "    phrase = re.sub(r\"\\'ll\", \" 'll\", phrase)\n",
    "    phrase = re.sub(r\"\\'ve\", \" 've\", phrase)\n",
    "    phrase = re.sub(r\"\\'’m\", \" 'm\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group up contigous white space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_space(text):\n",
    "    return \" \".join(text.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ' Expand the qoutation mark '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expand_qoute(text):\n",
    "    # remove punctuation first\n",
    "    out = []\n",
    "    for i in range(len(text)):\n",
    "        if text[i] == \"\\'\": \n",
    "            if(i!=0 and text[i-1] == ' '): #start qoute\n",
    "                out.append(\"' \")\n",
    "            elif(text[i+1] == ' ' and text[i-1]!=\" \"): #end qoute\n",
    "                out.append(\" '\")\n",
    "        else: out.append(text[i])\n",
    "    return \"\".join(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pad < end >"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def find_dot(text):\n",
    "    index = -1 \n",
    "    reverse_text = text[::-1]\n",
    "    for i in range(len(reverse_text)):\n",
    "        if(reverse_text[i] =='.'):\n",
    "            index = len(text)-i\n",
    "        else:\n",
    "            break\n",
    "    return index\n",
    "\n",
    "def pad_end_of_sentence(sentences):\n",
    "    out = []\n",
    "    for sentence in sentences:\n",
    "        if len(sentence) > 0 and sentence[-1] == '.':\n",
    "            out.append(sentence[:find_dot(sentence)-1])\n",
    "        else: \n",
    "            out.append(sentence)\n",
    "    return \" <end> \".join(out) + ' <end>'\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capital check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hey ! ! ! i 've just met you mr. prayuth.\n",
      "Captital_Dict: {'i': 'I', 'mr.': 'Mr.', 'prayuth': 'Prayuth'}\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "lowerToCapital = dict()\n",
    "lowerToCapital['i'] = 'I'\n",
    "def capital_clean(sentence):\n",
    "    words = word_tokenize(sentence)\n",
    "    for word in words[1:]:\n",
    "        try:\n",
    "            if(word[0].isupper() and word[1].islower()):\n",
    "                lowerToCapital[word.lower()] = word\n",
    "        except:\n",
    "            pass\n",
    "    return sentence.lower()\n",
    "    \n",
    "print(capital_clean(\"Hey ! ! ! I 've JUST met you Mr. Prayuth.\"))\n",
    "print(\"Captital_Dict:\", lowerToCapital)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def have_alphabet(sentence):\n",
    "    for char in sentence:\n",
    "        if char.isalpha():\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "def clean_data_main(data):\n",
    "    out = []\n",
    "    for line in data:\n",
    "        if(type(line) is float):\n",
    "            out.append([\" \"])\n",
    "            continue\n",
    "        sentences = sent_tokenize(line)\n",
    "        out_sentences = []\n",
    "        for sentence in sentences :\n",
    "            if not have_alphabet(sentence):\n",
    "                continue\n",
    "            x = capital_clean(sentence)\n",
    "            x = split_contraction(x)\n",
    "            x = remove_punc(x)\n",
    "            x = group_space(x)\n",
    "            out_sentences.append(x)     \n",
    "        out.append(pad_end_of_sentence(out_sentences))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reverse Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recontraction(phrase):\n",
    "    phrase = re.sub(r\"’\", \"'\", phrase)\n",
    "    # specific\n",
    "    phrase = re.sub(r\"will not\", \"won\\'t\", phrase)\n",
    "    phrase = re.sub(r\"can not\", \"can\\'t\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"them\", \"\\'em\", phrase)\n",
    "    phrase = re.sub(r\"until\", \"\\'til\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"you know\", \"y'know\", phrase)\n",
    "    \n",
    "    phrase = re.sub(r\"ing\", \"in'\", phrase)\n",
    "    \n",
    "    # general\n",
    "\n",
    "    phrase = re.sub(r\" n\\'t\", \"n't\", phrase)\n",
    "    phrase = re.sub(r\" \\'re\", \"'re\", phrase)\n",
    "    phrase = re.sub(r\" \\'s\", \"'s\", phrase)\n",
    "    phrase = re.sub(r\" \\'d\", \"'d\", phrase)\n",
    "    phrase = re.sub(r\" \\'ll\", \"'ll\", phrase)\n",
    "    phrase = re.sub(r\" \\'ve\", \"'ve\", phrase)\n",
    "    phrase = re.sub(r\" \\'’m\", \"'m\", phrase)\n",
    "    \n",
    "    return phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_capital(line):\n",
    "    out = []\n",
    "    startWord = True\n",
    "    for word in line.split():\n",
    "        if(startWord) :\n",
    "            out.append(word.capitalize())\n",
    "            startWord = False\n",
    "            continue\n",
    "        if word in lowerToCapital :\n",
    "            out.append(lowerToCapital[word])\n",
    "        else :\n",
    "            out.append(word)\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def remove_space_between_punctuation(line) :\n",
    "    out = ''\n",
    "    punctuation = set(string.punctuation)\n",
    "    for i in range(len(line)) :\n",
    "        try:\n",
    "            if line[i] == ' ' and line[i-1] in punctuation and line[i+1] in punctuation:\n",
    "                pass\n",
    "            else :\n",
    "                out+=line[i]\n",
    "        except :\n",
    "            pass\n",
    "    return out            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reverse_clean(data) :\n",
    "    endding_mark = ['.', '!', '?', ',']\n",
    "    print(data)\n",
    "    out = []\n",
    "    sentences = data.split('<end>')\n",
    "    for sentence in sentences:\n",
    "        if len(sentence)<=0:\n",
    "            continue\n",
    "        x = recontraction(sentence)\n",
    "        x = remove_space_between_punctuation(x)\n",
    "        x = apply_capital(x)\n",
    "        x = x.strip()\n",
    "        if(x[-1] not in endding_mark):\n",
    "            x+='.'    \n",
    "        print(x)\n",
    "        out.append(x)\n",
    "    return \" \".join(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i do n't want to know how to say that though <end> i want to know useful things <end> like where the good stores are <end> how much does champagne cost ? <end> stuff like chat <end> i have never in my life had to point out my head to someone <end>\n",
      "I don't want to know how to say that though.\n",
      "I want to know useful thin's.\n",
      "Like where the good stores are.\n",
      "How much does champagne cost ?\n",
      "Stuff like chat.\n",
      "I have never in my life had to point out my head to someone.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"I don't want to know how to say that though. I want to know useful thin's. Like where the good stores are. How much does champagne cost ? Stuff like chat. I have never in my life had to point out my head to someone.\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reverse_clean(\"i do n't want to know how to say that though <end> i want to know useful things <end> like where the good stores are <end> how much does champagne cost ? <end> stuff like chat <end> i have never in my life had to point out my head to someone <end>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
